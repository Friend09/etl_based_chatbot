{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRACTISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /Users/vamsi_mbmax/Library/CloudStorage/OneDrive-Personal/01_vam_PROJECTS/LEARNING/proj_PersonalProjects/dev/pract_pp_etl_based_chatbot/notebooks\n",
      "Main project folder: /Users/vamsi_mbmax/Library/CloudStorage/OneDrive-Personal/01_vam_PROJECTS/LEARNING/proj_PersonalProjects/dev/pract_pp_etl_based_chatbot\n",
      "Added to sys.path: /Users/vamsi_mbmax/Library/CloudStorage/OneDrive-Personal/01_vam_PROJECTS/LEARNING/proj_PersonalProjects/dev/pract_pp_etl_based_chatbot\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Get current working directory\n",
    "cwd = Path.cwd()\n",
    "print(f\"Current working directory: {cwd}\")\n",
    "\n",
    "# Get parent directory (main project folder)\n",
    "main_folder = cwd.parent\n",
    "print(f\"Main project folder: {main_folder}\")\n",
    "\n",
    "# Add the main folder to sys.path\n",
    "sys.path.append(str(main_folder))\n",
    "print(f\"Added to sys.path: {main_folder}\")\n",
    "\n",
    "# # Verify sys.path\n",
    "# print(\"\\nPaths in sys.path:\")\n",
    "# for path in sys.path:\n",
    "#     print(f\"  - {path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## CHATBOT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bot.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.logger import setup_logger, log_structured\n",
    "\n",
    "# create a logger for this module\n",
    "logger = setup_logger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-25 21:07:11,434 - __main__ - INFO - Initializing chatbot with model: gpt-4o-mini\n",
      "2025-03-25 21:07:11,434 - __main__ - INFO - Initializing chatbot with model: gpt-4o-mini\n",
      "2025-03-25 21:07:11,435 - __main__ - INFO - STRUCTURED_LOG: {'event': 'process_query_start', 'data': {'query_length': 31, 'query_preview': 'SELECT * FROM weather_forecast;'}}\n",
      "2025-03-25 21:07:11,435 - __main__ - INFO - STRUCTURED_LOG: {'event': 'process_query_start', 'data': {'query_length': 31, 'query_preview': 'SELECT * FROM weather_forecast;'}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'processed response for: SELECT * FROM weather_forecast;'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Chatbot:\n",
    "    def __init__(self, model_name=\"gpt-4o-mini\"):\n",
    "        logger.info(f\"Initializing chatbot with model: {model_name}\")\n",
    "        self.model_name = model_name\n",
    "\n",
    "    def process_query(self, query):\n",
    "        log_structured(\n",
    "            logger,\n",
    "            \"info\",\n",
    "            \"process_query_start\",\n",
    "            query_length=len(query),\n",
    "            query_preview=query[:50] if len(query) > 50 else query,\n",
    "        )\n",
    "        try:\n",
    "            response = f\"processed response for: {query}\"\n",
    "            logger.debug(\"Query processed successfully\")\n",
    "            log_structured(\n",
    "                logger, \"debug\", \"process_query_complete\", response_length=len(response)\n",
    "            )\n",
    "            return response\n",
    "        except Exception as e:\n",
    "            log_structured(\n",
    "                logger,\n",
    "                \"error\",\n",
    "                \"process_query_error\",\n",
    "                error=str(e),\n",
    "                query_length=len(query),\n",
    "            )\n",
    "            return \"I'm sorry, i couldn't process your request\"\n",
    "\n",
    "\n",
    "bot = Chatbot()\n",
    "bot.process_query(\"SELECT * FROM weather_forecast;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## CONFIG\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### logging_config.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import logging\n",
    "import logging.config\n",
    "import logging.handlers\n",
    "import os\n",
    "import functools\n",
    "from pathlib import Path\n",
    "\n",
    "from config.settings import LOG_LEVEL, LOG_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants for logging\n",
    "DEFAULT_LOG_FORMAT = \"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n",
    "DETAILED_LOG_FORMAT = \"%(asctime)s - %(name)s - %(levelname)s - %(filename)s:%(lineno)d - %(funcName)s - %(message)s\"\n",
    "MAX_LOG_SIZE = 10 * 1024 * 1024  # 10MB\n",
    "BACKUP_COUNT = 5  # Keep 5 backup files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map string log levels to logging constants\n",
    "LOG_LEVELS = {\n",
    "    \"DEBUG\": logging.DEBUG,\n",
    "    \"INFO\": logging.INFO,\n",
    "    \"WARNING\": logging.WARNING,\n",
    "    \"ERROR\": logging.ERROR,\n",
    "    \"CRITICAL\": logging.CRITICAL,\n",
    "}\n",
    "\n",
    "DEFAULT_LOG_LEVEL = logging.INFO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(LOG_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config.logging_constants import (\n",
    "    LOG_DIR,\n",
    "    ETL_LOG_FILE,\n",
    "    WEB_LOG_FILE,\n",
    "    DB_LOG_FILE,\n",
    "    DEFAULT_LOG_LEVEL,\n",
    "    LOG_LEVELS,\n",
    ")\n",
    "\n",
    "# Make constants available for import from this module\n",
    "__all__ = [\n",
    "    \"DEFAULT_LOG_LEVEL\",\n",
    "    \"LOG_LEVELS\",\n",
    "    \"LOG_DIR\",\n",
    "    \"ETL_LOG_FILE\",\n",
    "    \"WEB_LOG_FILE\",\n",
    "    \"DB_LOG_FILE\",\n",
    "    \"configure_logging\",\n",
    "    \"get_logger\",\n",
    "    \"set_log_level\",\n",
    "    \"log_function_call\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_logging(log_dir=\"logs\", level=logging.INFO):\n",
    "    \"\"\"\n",
    "    Configure the logging system with detailed settings.\n",
    "\n",
    "    Args:\n",
    "        log_dir: Directory to store logs\n",
    "        level: Default logging level\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Ensure log directory exists\n",
    "    Path(log_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Define logging configuration\n",
    "    config = {\n",
    "        \"version\": 1,\n",
    "        \"formatters\": {\n",
    "            \"standard\": {\n",
    "                \"format\": \"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n",
    "            },\n",
    "            \"detailed\": {\n",
    "                \"format\": \"%(asctime)s - %(name)s - %(levelname)s - %(module)s - %(funcName)s - %(message)s\"\n",
    "            },\n",
    "        },\n",
    "        \"handlers\": {\n",
    "            \"console\": {\n",
    "                \"class\": \"logging.StreamHandler\",\n",
    "                \"level\": level,\n",
    "                \"formatter\": \"standard\",\n",
    "                \"stream\": \"ext://sys.stdout\",\n",
    "            },\n",
    "            \"file\": {\n",
    "                \"class\": \"logging.handlers.RotatingFileHandler\",\n",
    "                \"level\": logging.DEBUG,\n",
    "                \"formatter\": \"detailed\",\n",
    "                \"filename\": os.path.join(log_dir, \"application.log\"),\n",
    "                \"maxBytes\": 10485760,  # 10MB\n",
    "                \"backupCount\": 5,\n",
    "            },\n",
    "            \"error_file\": {\n",
    "                \"class\": \"logging.handlers.RotatingFileHandler\",\n",
    "                \"level\": logging.ERROR,\n",
    "                \"formatter\": \"detailed\",\n",
    "                \"filename\": os.path.join(log_dir, \"errors.log\"),\n",
    "                \"maxBytes\": 10485760,  # 10MB\n",
    "                \"backupCount\": 5,\n",
    "            },\n",
    "        },\n",
    "        \"loggers\": {\n",
    "            \"\": {  # Root logger\n",
    "                \"handlers\": [\"console\", \"file\", \"error_file\"],\n",
    "                \"level\": logging.DEBUG,\n",
    "                \"propagate\": True,\n",
    "            }\n",
    "        },\n",
    "    }\n",
    "\n",
    "    # Apply configuration\n",
    "    logging.config.dictConfig(config)\n",
    "    logging.info(\"Logging system configured\")\n",
    "\n",
    "    return logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_logger(name, log_file=None, console=True, level=None):\n",
    "    logger = logging.getLogger(name)\n",
    "\n",
    "    # Only configure if handlers aren't already set up\n",
    "    if not logger.handlers:\n",
    "        # Set level (from param or env or default)\n",
    "        level = level or os.environ.get(\"LOG_LEVEL\", DEFAULT_LOG_LEVEL)\n",
    "        if isinstance(level, str):\n",
    "            level = LOG_LEVELS.get(level.lower(), DEFAULT_LOG_LEVEL)\n",
    "\n",
    "        logger.setLevel(level)\n",
    "\n",
    "        # Create formatter\n",
    "        formatter = logging.Formatter(\n",
    "            \"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n",
    "        )\n",
    "\n",
    "        # Add console handler if requested\n",
    "        if console:\n",
    "            console_handler = logging.StreamHandler()\n",
    "            console_handler.setFormatter(formatter)\n",
    "            logger.addHandler(console_handler)\n",
    "\n",
    "        # Add file handler if specified\n",
    "        if log_file:\n",
    "            # Ensure directory exists\n",
    "            log_dir = os.path.dirname(log_file)\n",
    "            Path(log_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            file_handler = logging.handlers.RotatingFileHandler(\n",
    "                log_file, maxBytes=10485760, backupCount=5  # 10MB\n",
    "            )\n",
    "            file_handler.setFormatter(formatter)\n",
    "            logger.addHandler(file_handler)\n",
    "\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 38\u001b[39m\n\u001b[32m     35\u001b[39m os.makedirs(LOG_DIR, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     37\u001b[39m \u001b[38;5;66;03m# Import and re-export constants\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlogging_constants\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     39\u001b[39m     DEFAULT_LOG_LEVEL,\n\u001b[32m     40\u001b[39m     LOG_LEVELS,\n\u001b[32m     41\u001b[39m     LOG_DIR,\n\u001b[32m     42\u001b[39m     ETL_LOG_FILE,\n\u001b[32m     43\u001b[39m     WEB_LOG_FILE,\n\u001b[32m     44\u001b[39m     DB_LOG_FILE,\n\u001b[32m     45\u001b[39m )\n\u001b[32m     47\u001b[39m \u001b[38;5;66;03m# Make constants available for import from this module\u001b[39;00m\n\u001b[32m     48\u001b[39m __all__ = [\n\u001b[32m     49\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mDEFAULT_LOG_LEVEL\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     50\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mLOG_LEVELS\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     58\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mlog_function_call\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     59\u001b[39m ]\n",
      "\u001b[31mImportError\u001b[39m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Logging configuration module.\n",
    "\n",
    "This module provides functions to configure the logging system for the application.\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "import logging\n",
    "import logging.config\n",
    "import logging.handlers\n",
    "import os\n",
    "import functools\n",
    "from pathlib import Path\n",
    "\n",
    "from config.settings import LOG_LEVEL, LOG_DIR\n",
    "\n",
    "# Constants for logging\n",
    "DEFAULT_LOG_FORMAT = \"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n",
    "DETAILED_LOG_FORMAT = \"%(asctime)s - %(name)s - %(levelname)s - %(filename)s:%(lineno)d - %(funcName)s - %(message)s\"\n",
    "MAX_LOG_SIZE = 10 * 1024 * 1024  # 10MB\n",
    "BACKUP_COUNT = 5  # Keep 5 backup files\n",
    "\n",
    "# Map string log levels to logging constants\n",
    "LOG_LEVELS = {\n",
    "    \"DEBUG\": logging.DEBUG,\n",
    "    \"INFO\": logging.INFO,\n",
    "    \"WARNING\": logging.WARNING,\n",
    "    \"ERROR\": logging.ERROR,\n",
    "    \"CRITICAL\": logging.CRITICAL,\n",
    "}\n",
    "\n",
    "DEFAULT_LOG_LEVEL = logging.INFO\n",
    "\n",
    "# Make sure log directory exists\n",
    "os.makedirs(LOG_DIR, exist_ok=True)\n",
    "\n",
    "# Import and re-export constants\n",
    "from .logging_constants import (\n",
    "    DEFAULT_LOG_LEVEL,\n",
    "    LOG_LEVELS,\n",
    "    LOG_DIR,\n",
    "    ETL_LOG_FILE,\n",
    "    WEB_LOG_FILE,\n",
    "    DB_LOG_FILE,\n",
    ")\n",
    "\n",
    "# Make constants available for import from this module\n",
    "__all__ = [\n",
    "    \"DEFAULT_LOG_LEVEL\",\n",
    "    \"LOG_LEVELS\",\n",
    "    \"LOG_DIR\",\n",
    "    \"ETL_LOG_FILE\",\n",
    "    \"WEB_LOG_FILE\",\n",
    "    \"DB_LOG_FILE\",\n",
    "    \"configure_logging\",\n",
    "    \"get_logger\",\n",
    "    \"set_log_level\",\n",
    "    \"log_function_call\",\n",
    "]\n",
    "\n",
    "\n",
    "def configure_logging(log_dir=\"logs\", level=logging.INFO):\n",
    "    \"\"\"\n",
    "    Configure the logging system with detailed settings.\n",
    "\n",
    "    Args:\n",
    "        log_dir: Directory to store logs\n",
    "        level: Default logging level\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Ensure log directory exists\n",
    "    Path(log_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Define logging configuration\n",
    "    config = {\n",
    "        \"version\": 1,\n",
    "        \"formatters\": {\n",
    "            \"standard\": {\n",
    "                \"format\": \"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n",
    "            },\n",
    "            \"detailed\": {\n",
    "                \"format\": \"%(asctime)s - %(name)s - %(levelname)s - %(module)s - %(funcName)s - %(message)s\"\n",
    "            },\n",
    "        },\n",
    "        \"handlers\": {\n",
    "            \"console\": {\n",
    "                \"class\": \"logging.StreamHandler\",\n",
    "                \"level\": level,\n",
    "                \"formatter\": \"standard\",\n",
    "                \"stream\": \"ext://sys.stdout\",\n",
    "            },\n",
    "            \"file\": {\n",
    "                \"class\": \"logging.handlers.RotatingFileHandler\",\n",
    "                \"level\": logging.DEBUG,\n",
    "                \"formatter\": \"detailed\",\n",
    "                \"filename\": os.path.join(log_dir, \"application.log\"),\n",
    "                \"maxBytes\": 10485760,  # 10MB\n",
    "                \"backupCount\": 5,\n",
    "            },\n",
    "            \"error_file\": {\n",
    "                \"class\": \"logging.handlers.RotatingFileHandler\",\n",
    "                \"level\": logging.ERROR,\n",
    "                \"formatter\": \"detailed\",\n",
    "                \"filename\": os.path.join(log_dir, \"errors.log\"),\n",
    "                \"maxBytes\": 10485760,  # 10MB\n",
    "                \"backupCount\": 5,\n",
    "            },\n",
    "        },\n",
    "        \"loggers\": {\n",
    "            \"\": {  # Root logger\n",
    "                \"handlers\": [\"console\", \"file\", \"error_file\"],\n",
    "                \"level\": logging.DEBUG,\n",
    "                \"propagate\": True,\n",
    "            }\n",
    "        },\n",
    "    }\n",
    "\n",
    "    # Apply configuration\n",
    "    logging.config.dictConfig(config)\n",
    "    logging.info(\"Logging system configured\")\n",
    "\n",
    "    return logging.getLogger()\n",
    "\n",
    "\n",
    "def get_logger(name, log_file=None, console=True, level=None):\n",
    "    \"\"\"\n",
    "    Get a configured logger instance.\n",
    "\n",
    "    Args:\n",
    "        name: Logger name\n",
    "        log_file: Optional log file path\n",
    "        console: Whether to log to console\n",
    "        level: Log level (defaults to DEFAULT_LOG_LEVEL)\n",
    "\n",
    "    Returns:\n",
    "        Logger instance\n",
    "    \"\"\"\n",
    "    logger = logging.getLogger(name)\n",
    "\n",
    "    # Only configure if handlers aren't already set up\n",
    "    if not logger.handlers:\n",
    "        # Set level (from param or env or default)\n",
    "        level = level or os.environ.get(\"LOG_LEVEL\", DEFAULT_LOG_LEVEL)\n",
    "        if isinstance(level, str):\n",
    "            level = LOG_LEVELS.get(level.lower(), DEFAULT_LOG_LEVEL)\n",
    "\n",
    "        logger.setLevel(level)\n",
    "\n",
    "        # Create formatter\n",
    "        formatter = logging.Formatter(\n",
    "            \"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n",
    "        )\n",
    "\n",
    "        # Add console handler if requested\n",
    "        if console:\n",
    "            console_handler = logging.StreamHandler()\n",
    "            console_handler.setFormatter(formatter)\n",
    "            logger.addHandler(console_handler)\n",
    "\n",
    "        # Add file handler if specified\n",
    "        if log_file:\n",
    "            # Ensure directory exists\n",
    "            log_dir = os.path.dirname(log_file)\n",
    "            Path(log_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            file_handler = logging.handlers.RotatingFileHandler(\n",
    "                log_file, maxBytes=10485760, backupCount=5  # 10MB\n",
    "            )\n",
    "            file_handler.setFormatter(formatter)\n",
    "            logger.addHandler(file_handler)\n",
    "\n",
    "    return logger\n",
    "\n",
    "\n",
    "def set_log_level(logger, level):\n",
    "    \"\"\"\n",
    "    Set log level for a logger and all its handlers.\n",
    "\n",
    "    Args:\n",
    "        logger: Logger to modify\n",
    "        level: New log level\n",
    "    \"\"\"\n",
    "    if isinstance(level, str):\n",
    "        level = LOG_LEVELS.get(level.lower(), DEFAULT_LOG_LEVEL)\n",
    "\n",
    "    logger.setLevel(level)\n",
    "    for handler in logger.handlers:\n",
    "        handler.setLevel(level)\n",
    "\n",
    "\n",
    "def log_function_call(func_or_logger=None):\n",
    "    \"\"\"\n",
    "    Decorator for logging function calls.\n",
    "\n",
    "    Can be used in two ways:\n",
    "    1. As a direct decorator: @log_function_call\n",
    "    2. With a logger: @log_function_call(logger)\n",
    "\n",
    "    Args:\n",
    "        func_or_logger: Function to decorate or logger to use\n",
    "\n",
    "    Returns:\n",
    "        Wrapped function or decorator function\n",
    "    \"\"\"\n",
    "    if func_or_logger is None or isinstance(func_or_logger, logging.Logger):\n",
    "        # Case 2: Called with logger or no args\n",
    "        logger = func_or_logger or logging.getLogger()\n",
    "\n",
    "        def decorator(func):\n",
    "            @functools.wraps(func)\n",
    "            def wrapper(*args, **kwargs):\n",
    "                logger.debug(f\"Calling {func.__name__}\")\n",
    "                try:\n",
    "                    result = func(*args, **kwargs)\n",
    "                    logger.debug(f\"Completed {func.__name__}\")\n",
    "                    return result\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"Error in {func.__name__}: {str(e)}\")\n",
    "                    raise\n",
    "\n",
    "            return wrapper\n",
    "\n",
    "        return decorator\n",
    "    else:\n",
    "        # Case 1: Called as direct decorator\n",
    "        func = func_or_logger\n",
    "        logger = logging.getLogger(func.__module__)\n",
    "\n",
    "        @functools.wraps(func)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            logger.debug(f\"Calling {func.__name__}\")\n",
    "            try:\n",
    "                result = func(*args, **kwargs)\n",
    "                logger.debug(f\"Completed {func.__name__}\")\n",
    "                return result\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error in {func.__name__}: {str(e)}\")\n",
    "                raise\n",
    "\n",
    "        return wrapper\n",
    "\n",
    "\n",
    "def get_log_level(level_name=None):\n",
    "    \"\"\"\n",
    "    Get the log level from a string.\n",
    "\n",
    "    Args:\n",
    "        level_name (str, optional): Log level name (DEBUG, INFO, etc.).\n",
    "            If None, will use LOG_LEVEL from settings.\n",
    "\n",
    "    Returns:\n",
    "        int: The log level constant (e.g., logging.INFO)\n",
    "    \"\"\"\n",
    "    if level_name is None:\n",
    "        level_name = LOG_LEVEL\n",
    "\n",
    "    level_name = level_name.upper()\n",
    "\n",
    "    # Map string log levels to logging constants\n",
    "    log_levels = {\n",
    "        \"DEBUG\": logging.DEBUG,\n",
    "        \"INFO\": logging.INFO,\n",
    "        \"WARNING\": logging.WARNING,\n",
    "        \"ERROR\": logging.ERROR,\n",
    "        \"CRITICAL\": logging.CRITICAL,\n",
    "    }\n",
    "\n",
    "    return log_levels.get(level_name, logging.INFO)\n",
    "\n",
    "\n",
    "def create_log_formatter(detailed=False):\n",
    "    \"\"\"\n",
    "    Create a log formatter.\n",
    "\n",
    "    Args:\n",
    "        detailed (bool): Whether to use detailed format.\n",
    "            Detailed format includes filename, line number, and function name.\n",
    "\n",
    "    Returns:\n",
    "        logging.Formatter: A log formatter\n",
    "    \"\"\"\n",
    "    log_format = DETAILED_LOG_FORMAT if detailed else DEFAULT_LOG_FORMAT\n",
    "    return logging.Formatter(log_format)\n",
    "\n",
    "\n",
    "def create_file_handler(log_file, level=None, formatter=None):\n",
    "    \"\"\"\n",
    "    Create a rotating file handler for logging.\n",
    "\n",
    "    Args:\n",
    "        log_file (str): Path to the log file.\n",
    "        level (int, optional): Log level. If None, will use level from settings.\n",
    "        formatter (logging.Formatter, optional): Log formatter.\n",
    "            If None, will create a default formatter.\n",
    "\n",
    "    Returns:\n",
    "        logging.Handler: A file handler for logging\n",
    "    \"\"\"\n",
    "    if level is None:\n",
    "        level = get_log_level()\n",
    "\n",
    "    if formatter is None:\n",
    "        formatter = create_log_formatter()\n",
    "\n",
    "    # Create directory for log file if it doesn't exist\n",
    "    os.makedirs(os.path.dirname(log_file), exist_ok=True)\n",
    "\n",
    "    # Create a rotating file handler\n",
    "    handler = logging.handlers.RotatingFileHandler(\n",
    "        log_file, maxBytes=MAX_LOG_SIZE, backupCount=BACKUP_COUNT\n",
    "    )\n",
    "\n",
    "    handler.setLevel(level)\n",
    "    handler.setFormatter(formatter)\n",
    "\n",
    "    return handler\n",
    "\n",
    "\n",
    "def create_console_handler(level=None, formatter=None):\n",
    "    \"\"\"\n",
    "    Create a console handler for logging.\n",
    "\n",
    "    Args:\n",
    "        level (int, optional): Log level. If None, will use level from settings.\n",
    "        formatter (logging.Formatter, optional): Log formatter.\n",
    "            If None, will create a default formatter.\n",
    "\n",
    "    Returns:\n",
    "        logging.Handler: A console handler for logging\n",
    "    \"\"\"\n",
    "    if level is None:\n",
    "        level = get_log_level()\n",
    "\n",
    "    if formatter is None:\n",
    "        formatter = create_log_formatter()\n",
    "\n",
    "    # Create a console handler\n",
    "    handler = logging.StreamHandler(sys.stdout)\n",
    "    handler.setLevel(level)\n",
    "    handler.setFormatter(formatter)\n",
    "\n",
    "    return handler\n",
    "\n",
    "\n",
    "def configure_logger(\n",
    "    logger, level=None, add_console_handler=True, log_file=None, detailed=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Configure a logger with handlers and formatters.\n",
    "\n",
    "    Args:\n",
    "        logger (logging.Logger): The logger to configure.\n",
    "        level (int, optional): Log level. If None, will use level from settings.\n",
    "        add_console_handler (bool): Whether to add a console handler.\n",
    "        log_file (str, optional): Path to the log file.\n",
    "            If None, no file handler will be added.\n",
    "        detailed (bool): Whether to use detailed format.\n",
    "\n",
    "    Returns:\n",
    "        logging.Logger: The configured logger\n",
    "    \"\"\"\n",
    "    if level is None:\n",
    "        level = get_log_level()\n",
    "\n",
    "    # Set the logger's level\n",
    "    logger.setLevel(level)\n",
    "\n",
    "    # Remove any existing handlers to avoid duplicates\n",
    "    while logger.handlers:\n",
    "        logger.removeHandler(logger.handlers[0])\n",
    "\n",
    "    # Create formatter\n",
    "    formatter = create_log_formatter(detailed=detailed)\n",
    "\n",
    "    # Add console handler if requested\n",
    "    if add_console_handler:\n",
    "        console_handler = create_console_handler(level=level, formatter=formatter)\n",
    "        logger.addHandler(console_handler)\n",
    "\n",
    "    # Add file handler if log_file is specified\n",
    "    if log_file:\n",
    "        file_handler = create_file_handler(log_file, level=level, formatter=formatter)\n",
    "        logger.addHandler(file_handler)\n",
    "\n",
    "    # Don't propagate to root logger if this is not the root logger\n",
    "    if logger.name != \"root\":\n",
    "        logger.propagate = False\n",
    "\n",
    "    return logger\n",
    "\n",
    "\n",
    "def get_component_logger(\n",
    "    component, subcomponent=None, level=None, add_console_handler=True, detailed=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Get a logger for a specific component.\n",
    "\n",
    "    Args:\n",
    "        component (str): The component name (e.g., 'etl', 'web').\n",
    "        subcomponent (str, optional): The subcomponent name (e.g., 'extractor').\n",
    "        level (int, optional): Log level. If None, will use level from settings.\n",
    "        add_console_handler (bool): Whether to add a console handler.\n",
    "        detailed (bool): Whether to use detailed format.\n",
    "\n",
    "    Returns:\n",
    "        logging.Logger: The configured logger\n",
    "    \"\"\"\n",
    "    # Construct logger name\n",
    "    logger_name = component\n",
    "    if subcomponent:\n",
    "        logger_name = f\"{component}.{subcomponent}\"\n",
    "\n",
    "    # Get or create the logger\n",
    "    logger = logging.getLogger(logger_name)\n",
    "\n",
    "    # Determine log file based on component\n",
    "    log_file = os.path.join(LOG_DIR, f\"{component}.log\")\n",
    "\n",
    "    # Configure the logger\n",
    "    configure_logger(\n",
    "        logger,\n",
    "        level=level,\n",
    "        add_console_handler=add_console_handler,\n",
    "        log_file=log_file,\n",
    "        detailed=detailed,\n",
    "    )\n",
    "\n",
    "    return logger\n",
    "\n",
    "\n",
    "def configure_root_logger():\n",
    "    \"\"\"\n",
    "    Configure the root logger for the application.\n",
    "\n",
    "    Returns:\n",
    "        logging.Logger: The configured root logger\n",
    "    \"\"\"\n",
    "    # Get the root logger\n",
    "    root_logger = logging.getLogger()\n",
    "\n",
    "    # Configure with both console and file handlers\n",
    "    log_file = os.path.join(LOG_DIR, \"app.log\")\n",
    "    configure_logger(\n",
    "        root_logger,\n",
    "        level=get_log_level(),\n",
    "        add_console_handler=True,\n",
    "        log_file=log_file,\n",
    "        detailed=True,\n",
    "    )\n",
    "\n",
    "    root_logger.info(\"Root logger configured\")\n",
    "    return root_logger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### logging_constants.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_DIR = Path(\"logs\")\n",
    "ETL_LOG_FILE = str(LOG_DIR / \"etl\" / \"etl.log\")\n",
    "WEB_LOG_FILE = str(LOG_DIR / \"web\" / \"web.log\")\n",
    "DB_LOG_FILE = str(LOG_DIR / \"db\" / \"db.log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log levels\n",
    "DEFAULT_LOG_LEVEL = logging.INFO\n",
    "LOG_LEVELS = {\n",
    "    \"debug\": logging.DEBUG,\n",
    "    \"info\": logging.INFO,\n",
    "    \"warning\": logging.WARNING,\n",
    "    \"error\": logging.ERROR,\n",
    "    \"critical\": logging.CRITICAL,\n",
    "    \"production\": logging.WARNING,\n",
    "    \"development\": logging.DEBUG,\n",
    "    \"testing\": logging.DEBUG,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### settings.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the already defined cwd variable from cell 1\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "CONFIG_DIR = os.path.join(PROJECT_ROOT, \"config\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(os.path.join(PROJECT_ROOT, \".env\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'INFO  # DEBUG, INFO, WARNING, ERROR, OR CRITICAL'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LOG_LEVEL = os.getenv(\"LOG_LEVEL\", \"INFO\").upper()\n",
    "LOG_LEVEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## DATABASE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### db_connector.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from psycopg2.extras import RealDictCursor, DictCursor, Json\n",
    "import logging\n",
    "from contextlib import contextmanager\n",
    "import json\n",
    "from datetime import datetime\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config.settings import DB_CONFIG\n",
    "from utils.logger import get_component_logger, log_db_function, log_structured\n",
    "\n",
    "logger = get_component_logger(\"db\", \"connector\")\n",
    "\n",
    "\n",
    "class DatabaseConnectionError(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "class DatabaseQueryError(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "class DatabaseConnector:\n",
    "    def __init__(self, config=None, max_retries=3, retry_delay=1):\n",
    "        self.config = config or DB_CONFIG\n",
    "        self.max_retries = max_retries\n",
    "        self.retry_delay = retry_delay\n",
    "        self._test_connection()\n",
    "\n",
    "    def _test_connection(self):\n",
    "        try:\n",
    "            with self.get_connection() as conn:\n",
    "                with conn.cursor() as cursor:\n",
    "                    cursor.execute(\"SELECT 1\")\n",
    "                    result = cursor.fetchone()\n",
    "                    if result and result[0] == 1:\n",
    "                        logger.debug(\"database connection test successful\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"database connection test failed {e}\")\n",
    "            raise DatabaseConnectionError(f\"failed to connect to db {e}\")\n",
    "\n",
    "    @contextmanager\n",
    "    @log_db_function\n",
    "    def get_connection(self):\n",
    "        \"\"\"\n",
    "        Context manager that yields a database connection.\n",
    "        Automatically closes the connection when exiting the context.\n",
    "        Implements retry logic for transient connection failures.\n",
    "\n",
    "        Yields:\n",
    "            psycopg2.connection: A PostgreSQL database connection\n",
    "\n",
    "        Raises:\n",
    "            DatabaseConnectionError: If connection cannot be established after retries\n",
    "        \"\"\"\n",
    "        conn = None\n",
    "        attempt = 0\n",
    "        last_error = None\n",
    "\n",
    "        while attempt < self.max_retries:\n",
    "            try:\n",
    "                logger.debug(\n",
    "                    f\"Connecting to the PostgreSQL database (attempt {attempt+1})\"\n",
    "                )\n",
    "                conn = psycopg2.connect(**self.config)\n",
    "                yield conn\n",
    "                return\n",
    "            except psycopg2.Error as e:\n",
    "                last_error = e\n",
    "                logger.warning(f\"Database connection error (attempt {attempt+1}): {e}\")\n",
    "\n",
    "                if conn is not None:\n",
    "                    try:\n",
    "                        conn.close()\n",
    "                    except:\n",
    "                        pass  # Ignore errors on close\n",
    "\n",
    "                # Add jitter to retry delay to avoid thundering herd\n",
    "                jitter = random.uniform(0, 0.5)\n",
    "                retry_wait = self.retry_delay * (2**attempt) + jitter\n",
    "                logger.debug(f\"Retrying in {retry_wait:.2f} seconds\")\n",
    "                time.sleep(retry_wait)\n",
    "                attempt += 1\n",
    "\n",
    "        # If we get here, all attempts failed\n",
    "        logger.error(f\"All {self.max_retries} connection attempts failed\")\n",
    "        raise DatabaseConnectionError(\n",
    "            f\"Failed to connect after {self.max_retries} attempts: {last_error}\"\n",
    "        )\n",
    "\n",
    "    @contextmanager\n",
    "    def get_cursor(self, cursor_factory=None, named=False):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'host': 'localhost',\n",
       " 'port': 5432,\n",
       " 'database': 'weather_db',\n",
       " 'user': 'postgres',\n",
       " 'password': ''}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DB_CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create_weather_stats.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from database.db_connector import DatabaseConnector\n",
    "from utils.logger import get_component_logger\n",
    "\n",
    "logger = get_component_logger(\"db\", \"schema\")\n",
    "\n",
    "\n",
    "def create_weather_stats_table():\n",
    "    db = DatabaseConnector()\n",
    "\n",
    "    try:\n",
    "        schema_file = os.path.join(Path.cwd(), \"weather_stats.sql\")\n",
    "        with open(schema_file, \"r\") as f:\n",
    "            sql = f.read()\n",
    "\n",
    "        with db.transaction() as cursor:\n",
    "            cursor.execute(sql)\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/vamsi_mbmax/Library/CloudStorage/OneDrive-Personal/01_vam_PROJECTS/LEARNING/proj_PersonalProjects/dev/pract_pp_etl_based_chatbot/notebooks/weather_stats.sql'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join(Path.cwd(), \"weather_stats.sql\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### db_utils.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Any, Optional, Tuple, Union\n",
    "\n",
    "from database.db_connector import DatabaseConnector\n",
    "from utils.logger import get_component_logger, log_db_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatabaseError(Exception):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_value_from_result(result, key_or_index, default=None):\n",
    "    if result is None:\n",
    "        return default\n",
    "\n",
    "    try:\n",
    "        if isinstance(result, dict):\n",
    "            return result.get(key_or_index, default)\n",
    "        elif isinstance(result, (list, tuple)):\n",
    "            # If the key_or_index is a string but the result is a tuple,\n",
    "            # we need to convert it to an integer index\n",
    "            if isinstance(key_or_index, str) and key_or_index == \"location_id\":\n",
    "                return result[0]  # Assume first column is location_id\n",
    "            elif isinstance(key_or_index, str) and key_or_index == \"weather_id\":\n",
    "                return result[0]  # Assume first column is weather_id\n",
    "            elif isinstance(key_or_index, str) and key_or_index == \"forecast_id\":\n",
    "                return result[0]  # Assume first column is forecast_id\n",
    "            elif isinstance(key_or_index, str) and key_or_index == \"report_id\":\n",
    "                return result[0]  # Assume first column is report_id\n",
    "            elif isinstance(key_or_index, int):\n",
    "                return (\n",
    "                    result[key_or_index] if 0 <= key_or_index < len(result) else default\n",
    "                )\n",
    "            else:\n",
    "                return default\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"Failed to extract {key_or_index} from result: {str(e)}\")\n",
    "        return default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "@log_db_function\n",
    "def get_or_create_location(\n",
    "    city_name: str,\n",
    "    country: str,\n",
    "    latitude: float = None,\n",
    "    longitude: float = None,\n",
    "    timezone: str = None,\n",
    "    population: int = None,\n",
    ") -> int:\n",
    "    db = DatabaseConnector()\n",
    "\n",
    "    try:\n",
    "        query = \"\"\"\n",
    "            SELECT location_id FROM locations\n",
    "            WHERE city_name = %s AND country = %s\n",
    "        \"\"\"\n",
    "        result = db.execute_query(query, (city_name, country))\n",
    "\n",
    "        if result:\n",
    "            # Extract location_id safely\n",
    "            location_id = get_value_from_result(result[0], \"location_id\")\n",
    "            if location_id is not None:\n",
    "                logger.debug(\n",
    "                    f\"Found existing location ID {location_id} for {city_name}, {country}\"\n",
    "                )\n",
    "                return location_id\n",
    "\n",
    "        # If not found or location_id was None, create a new location\n",
    "        logger.info(f\"Creating new location for {city_name}, {country}\")\n",
    "        insert_query = \"\"\"\n",
    "            INSERT INTO locations (city_name, country, latitude, longitude, timezone, population)\n",
    "            VALUES (%s, %s, %s, %s, %s, %s)\n",
    "            RETURNING location_id\n",
    "        \"\"\"\n",
    "\n",
    "        result = db.execute_query(\n",
    "            insert_query,\n",
    "            (city_name, country, latitude, longitude, timezone, population),\n",
    "        )\n",
    "\n",
    "        if not result:\n",
    "            raise DatabaseError(f\"Failed to create location for {city_name}, {country}\")\n",
    "\n",
    "        # Extract location_id safely\n",
    "        location_id = get_value_from_result(result[0], \"location_id\")\n",
    "        if location_id is None:\n",
    "            # If still None, try to access as first element of tuple\n",
    "            location_id = get_value_from_result(result[0], 0)\n",
    "\n",
    "        if location_id is None:\n",
    "            raise DatabaseError(\"Could not extract location_id from database result\")\n",
    "\n",
    "        logger.info(f\"Created new location with ID {location_id}\")\n",
    "        return location_id\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error getting or creating location: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@log_db_function\n",
    "def save_current_weather():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### init_db.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### models.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sample_data.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### schema.sql\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### weather_stats.sql\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## ETL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data_loader.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data_processor.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### etl_pipeline.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### extract.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### transform.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### weather_collector.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## EXAMPLES\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### logging_example.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## TESTS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data (directory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### logger-tests.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test_chatbot.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test_data_processor.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test_database.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test_db_utils.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test_location_validator.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test_logging.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test_weather_collector.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## UTILS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check_api_availability.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check_api_key.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cleanup.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### location_validator.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### logger.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### logger_migration.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test_city_format.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## WEB\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### api.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### app.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### chatbot.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### chatbot_utils.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### routes.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### static (directory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### templates (directory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## ROOT DIRECTORY FILES\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### main.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setup.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
